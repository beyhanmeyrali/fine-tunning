"""
LLaMA-Factory Web Interface Demo for GMKtec K11
===============================================

Your first introduction to zero-code fine-tuning through a beautiful web interface.
This script helps you launch and understand the LLaMA-Factory WebUI.

Author: Beyhan MEYRALI
Hardware: GMKtec K11 (AMD Ryzen 9 8945HS + Radeon 780M)
"""

import os
import sys
import subprocess
import webbrowser
from pathlib import Path
import time

# AMD ROCm optimization for K11
os.environ["PYTORCH_ROCM_ARCH"] = "gfx1100"
os.environ["HSA_OVERRIDE_GFX_VERSION"] = "11.0.0"

def check_installation():
    """Verify LLaMA-Factory is properly installed"""
    try:
        import llamafactory
        print(f"‚úÖ LLaMA-Factory {llamafactory.__version__} detected")
        return True
    except ImportError:
        print("‚ùå LLaMA-Factory not found. Installing...")
        subprocess.run([sys.executable, "-m", "pip", "install", "llamafactory[torch,metrics]"])
        return True

def check_amd_gpu():
    """Check AMD GPU availability"""
    try:
        import torch
        if torch.cuda.is_available():
            device_name = torch.cuda.get_device_name(0)
            print(f"‚úÖ GPU detected: {device_name}")
            return True
        else:
            print("‚ö†Ô∏è  No GPU detected, using CPU (slower but works)")
            return False
    except Exception as e:
        print(f"‚ö†Ô∏è  GPU check failed: {e}")
        return False

def create_sample_dataset():
    """Create a simple dataset for demo purposes"""
    dataset_dir = Path("datasets")
    dataset_dir.mkdir(exist_ok=True)
    
    sample_data = [
        {
            "instruction": "What is machine learning?",
            "input": "",
            "output": "Machine learning is a branch of artificial intelligence that enables computers to learn and make decisions from data without explicit programming."
        },
        {
            "instruction": "Explain fine-tuning in simple terms",
            "input": "",
            "output": "Fine-tuning is like teaching a smart student (pre-trained model) a new subject by showing examples specific to that subject, rather than starting their education from scratch."
        },
        {
            "instruction": "What are the benefits of using LoRA?",
            "input": "",
            "output": "LoRA (Low-Rank Adaptation) allows efficient fine-tuning by updating only a small subset of model parameters, reducing memory usage by up to 95% while maintaining performance."
        },
        {
            "instruction": "How does quantization help in AI training?",
            "input": "",
            "output": "Quantization reduces model size and memory usage by representing weights with fewer bits (e.g., 4-bit instead of 16-bit), making large models trainable on consumer hardware."
        },
        {
            "instruction": "What is the GMKtec K11 good for in AI?",
            "input": "",
            "output": "The GMKtec K11 with AMD Ryzen 9 8945HS and Radeon 780M is excellent for AI fine-tuning, offering 32GB+ RAM for large datasets and AMD GPU acceleration with ROCm support."
        }
    ]
    
    import json
    with open(dataset_dir / "demo_dataset.json", "w") as f:
        json.dump(sample_data, f, indent=2)
    
    print(f"‚úÖ Sample dataset created at {dataset_dir / 'demo_dataset.json'}")
    return dataset_dir / "demo_dataset.json"

def launch_webui():
    """Launch the LLaMA-Factory Web Interface"""
    print("\nüöÄ Launching LLaMA-Factory Web Interface...")
    print("üìç This will open in your browser at: http://localhost:7860")
    print("\nüí° What you can do in the Web Interface:")
    print("   ‚Ä¢ Select models from 100+ options")
    print("   ‚Ä¢ Upload and configure datasets")
    print("   ‚Ä¢ Choose training methods (LoRA, QLoRA, DPO)")
    print("   ‚Ä¢ Monitor training progress in real-time")
    print("   ‚Ä¢ Export trained models")
    print("\n‚è±Ô∏è  Starting in 3 seconds...")
    
    time.sleep(3)
    
    try:
        # Launch the web interface
        result = subprocess.run([
            "llamafactory-cli", "webui"
        ], cwd=os.getcwd())
        
    except KeyboardInterrupt:
        print("\nüõë WebUI stopped by user")
    except Exception as e:
        print(f"‚ùå Error launching WebUI: {e}")
        print("üí° Try running manually: llamafactory-cli webui")

def print_webui_guide():
    """Print a guide for using the Web Interface"""
    print("\n" + "="*60)
    print("üéØ WEB INTERFACE QUICK START GUIDE")
    print("="*60)
    
    print("\n1Ô∏è‚É£ MODEL SELECTION:")
    print("   ‚Ä¢ Go to 'Train' tab")
    print("   ‚Ä¢ Choose 'Model name': qwen2 (good for beginners)")
    print("   ‚Ä¢ Select 'Model path': Qwen/Qwen2.5-1.5B-Instruct")
    
    print("\n2Ô∏è‚É£ DATASET CONFIGURATION:")
    print("   ‚Ä¢ Select 'Dataset': Browse and upload your demo_dataset.json")
    print("   ‚Ä¢ Choose 'Template': qwen")
    print("   ‚Ä¢ Set 'Cutoff length': 1024")
    
    print("\n3Ô∏è‚É£ TRAINING SETTINGS (K11 OPTIMIZED):")
    print("   ‚Ä¢ Training stage: Supervised Fine-Tuning")
    print("   ‚Ä¢ Fine-tuning method: LoRA")
    print("   ‚Ä¢ LoRA rank: 16")
    print("   ‚Ä¢ LoRA alpha: 32")
    print("   ‚Ä¢ Batch size: 2")
    print("   ‚Ä¢ Learning rate: 5e-5")
    print("   ‚Ä¢ Epochs: 3")
    
    print("\n4Ô∏è‚É£ ADVANCED SETTINGS:")
    print("   ‚Ä¢ Enable quantization: 4-bit")
    print("   ‚Ä¢ Gradient accumulation: 8")
    print("   ‚Ä¢ Save steps: 500")
    
    print("\n5Ô∏è‚É£ START TRAINING:")
    print("   ‚Ä¢ Click 'Start' button")
    print("   ‚Ä¢ Monitor progress in real-time")
    print("   ‚Ä¢ Expected time: 20-30 minutes on K11")
    
    print("\n6Ô∏è‚É£ AFTER TRAINING:")
    print("   ‚Ä¢ Go to 'Export' tab")
    print("   ‚Ä¢ Export as merged model or LoRA adapters")
    print("   ‚Ä¢ Test your model in 'Chat' tab")
    
    print("\nüí° Pro Tips:")
    print("   ‚Ä¢ Use 'Preview' to check your data format")
    print("   ‚Ä¢ Monitor GPU usage in Task Manager")
    print("   ‚Ä¢ Save configurations for future use")
    
    print("\nüîó Useful Links:")
    print("   ‚Ä¢ Documentation: https://llamafactory.readthedocs.io/")
    print("   ‚Ä¢ Supported Models: 100+ including Qwen, LLaMA, Mistral")
    print("   ‚Ä¢ GitHub Issues: For troubleshooting")

def main():
    """Main demo function"""
    print("üéØ LLaMA-Factory Web Interface Demo")
    print("===================================")
    print("Hardware: GMKtec K11 (AMD Ryzen 9 8945HS + Radeon 780M)")
    print("Goal: Learn zero-code fine-tuning through beautiful web interface")
    
    # Step 1: Check installation
    if not check_installation():
        return
    
    # Step 2: Check GPU
    gpu_available = check_amd_gpu()
    
    # Step 3: Create demo dataset
    dataset_path = create_sample_dataset()
    
    # Step 4: Print usage guide
    print_webui_guide()
    
    # Step 5: Launch WebUI
    user_input = input("\nüöÄ Ready to launch Web Interface? (y/n): ")
    if user_input.lower() in ['y', 'yes']:
        launch_webui()
    else:
        print("üí° You can launch manually later with: llamafactory-cli webui")
    
    print("\n‚ú® Demo completed!")
    print("üéØ Next steps:")
    print("   ‚Ä¢ Experiment with different models in WebUI")
    print("   ‚Ä¢ Try advanced training methods (DPO, PPO)")
    print("   ‚Ä¢ Check out 02_rlhf_training.py for programmatic training")

if __name__ == "__main__":
    main()