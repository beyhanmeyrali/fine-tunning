# Ä°lk Fine-Tuning Deneyiminiz: Qwen 3 0.6B

**OluÅŸturan:** [Beyhan MEYRALI](https://www.linkedin.com/in/beyhanmeyrali/)

BaÅŸlangÄ±Ã§ iÃ§in mÃ¼kemmel seÃ§im! Qwen 3 0.6B hÄ±zlÄ±, hafif ve [GMKtec K11](https://www.gmktec.com/products/amd-ryzen%E2%84%A2-9-8945hs-nucbox-k11?srsltid=AfmBOoq1AWYe9b93BdKLQKjQzuFoihgz8oXDO5Rn_S_Liy1jAweHo6NH&variant=30dc8500-fc10-4c45-bb52-5ef5caf7d515) sisteminizde fine-tuning Ã¶ÄŸrenmek iÃ§in idealdir.

## ğŸ¯ Ne YapacaÄŸÄ±z? (Ã‡ok Basit AnlatÄ±m)

**Fine-tuning** = HazÄ±r bir yapay zeka modelini kendi ihtiyaÃ§larÄ±nÄ±za gÃ¶re eÄŸitme

**Ã–rnek**: ChatGPT gibi bir model var, ama siz onun:
- ğŸ‡¹ğŸ‡· **TÃ¼rkÃ§e daha iyi konuÅŸmasÄ±nÄ±** istiyorsunuz
- ğŸ’¼ **Sizin iÅŸinizi daha iyi anlamasÄ±nÄ±** istiyorsunuz  
- ğŸ¨ **Sizin tarzÄ±nÄ±zda yazmasÄ±nÄ±** istiyorsunuz
- ğŸ¤– **Sizi tanÄ±masÄ±nÄ±** istiyorsunuz

Ä°ÅŸte fine-tuning tam da bunu yapar!

## ğŸ” Bu Proje Tam Olarak Ne Yapacak?

### BaÅŸlangÄ±Ã§ Durumu (EÄŸitim Ã–ncesi):
```
Sen: Merhaba, kendini tanÄ±t
Model: Merhaba! Ben yapay zeka bir asistanÄ±m...
```

### Final Durumu (EÄŸitim SonrasÄ±):
```
Sen: Merhaba, kendini tanÄ±t  
Model: Merhaba! Ben Beyhan MEYRALI tarafÄ±ndan fine-tuning ile eÄŸitilmiÅŸ 
       bir AI asistanÄ±yÄ±m. GenAI konularÄ±nda uzmanlaÅŸtÄ±m ve TÃ¼rkÃ§e 
       konuÅŸabilirim. LinkedIn: https://www.linkedin.com/in/beyhanmeyrali/
```

## âœ… Qwen 3 0.6B Neden BaÅŸlangÄ±Ã§ Ä°Ã§in MÃ¼kemmel?

**ğŸš€ SÃ¼per HÄ±zlÄ±**: Saatlerce deÄŸil, 15 dakikada eÄŸitim tamamlanÄ±r  
**ğŸ’¾ DÃ¼ÅŸÃ¼k HafÄ±za**: Sadece ~2GB VRAM kullanÄ±r  
**ğŸ¯ YÃ¼ksek Kalite**: Boyutuna gÃ¶re ÅŸaÅŸÄ±rtÄ±cÄ± derecede iyi performans  
**ğŸ”§ Kolay Kurulum**: Ollama ile mÃ¼kemmel Ã§alÄ±ÅŸÄ±r  
**ğŸ’¸ Ekonomik**: BÃ¼yÃ¼k modellerde hata yapma korkusu yok

### DiÄŸer Modeller ile KarÅŸÄ±laÅŸtÄ±rma:
| Model | Boyut | EÄŸitim SÃ¼resi | RAM Gereksinimi | BaÅŸlangÄ±Ã§ Ä°Ã§in |
|-------|--------|---------------|-----------------|----------------|
| **Qwen 3 0.6B** âœ… | 600MB | 15-30 dakika | 2GB | ğŸŸ¢ MÃ¼kemmel |
| GPT-3.5 Equivalent | 7GB | 2-4 saat | 8GB+ | ğŸŸ¡ Orta |
| LLaMA 7B | 14GB | 4-8 saat | 16GB+ | ğŸ”´ Zor |

## ğŸ“‹ Gereksinimler (Ã‡ok DetaylÄ±)

### ğŸ’» DonanÄ±m (Sizde Zaten Var)
- âœ… **GMKtec K11**: AMD Ryzen 9 8945HS + Radeon 780M  
- âœ… **RAM**: 32GB (8GB yeterli ama sizde daha fazla var)
- âœ… **Disk**: 5GB boÅŸ alan (model + veri iÃ§in)
- âœ… **ROCm**: AMD GPU desteÄŸi kurulu

### ğŸ› ï¸ YazÄ±lÄ±m (Kurulacak)
```bash
# 1. Python kontrol edin (3.8+ gerekli)
python --version
# Ã‡Ä±ktÄ±: Python 3.11.x gibi olmalÄ±

# 2. Conda kontrol edin 
conda --version
# Ã‡Ä±ktÄ±: conda 23.x.x gibi olmalÄ±

# 3. Git kontrol edin
git --version  
# Ã‡Ä±ktÄ±: git version 2.x.x gibi olmalÄ±
```

### ğŸ“¶ Ä°nternet BaÄŸlantÄ±sÄ±
- **Ä°lk kurulum**: ~2GB indirme (model + kÃ¼tÃ¼phaneler)
- **Sonraki kullanÄ±mlar**: Ä°nternet gerekmez (tamamen yerel)

## ğŸš€ AdÄ±m AdÄ±m Kurulum (HiÃ§ Deneyim Gerekmez)

### AdÄ±m 1: KlasÃ¶re Girin
```bash
# Terminal/Command Prompt aÃ§Ä±n
# Windows: Win+R -> cmd -> Enter
# Proje klasÃ¶rÃ¼ne gidin
cd D:\cabs\workspace\ai_bm\fine_tunning\00-first-time-beginner
```

### AdÄ±m 2: Python OrtamÄ± HazÄ±rlayÄ±n (Ä°steÄŸe BaÄŸlÄ± ama Ã–nerilen)
```bash
# Yeni bir conda ortamÄ± oluÅŸturun
conda create -n qwen-finetune python=3.11
conda activate qwen-finetune

# Veya mevcut ortamÄ±nÄ±zÄ± kullanabilirsiniz
# (Sadece yukarÄ±dakilerden birini yapÄ±n)
```

### AdÄ±m 3: Gerekli Paketleri Kurun
```bash
# AMD GPU destekli PyTorch (Ã–NEMLÄ°!)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6

# Fine-tuning kÃ¼tÃ¼phaneleri
pip install transformers datasets accelerate
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
pip install ollama requests

# Ä°steÄŸe baÄŸlÄ±: Jupyter notebook desteÄŸi
pip install jupyter notebook
```

### AdÄ±m 4: Kurulumu Test Edin
```bash
python test_setup.py
```

**BaÅŸarÄ±lÄ± Ã§Ä±ktÄ± ÅŸÃ¶yle gÃ¶rÃ¼nmeli:**
```
âœ… Python 3.11.x detected
âœ… PyTorch with AMD ROCm support
âœ… GPU: AMD Radeon 780M 
âœ… Transformers library ready
âœ… Unsloth library ready
âœ… All systems ready for fine-tuning!
```

**âŒ Hata alÄ±rsanÄ±z:**
- PyTorch ROCm kurulumunu tekrar yapÄ±n
- Python versiyonunuzu kontrol edin (3.8+ gerekli)

## ğŸ“Š Veri Seti OluÅŸturma (Ã‡ok Ã–nemli KÄ±sÄ±m)

### Ne YapacaÄŸÄ±z?
Model size **sizi tanÄ±yacak** ve **GenAI konularÄ±nda uzmanlaÅŸacak** veriler hazÄ±rlayacaÄŸÄ±z.

### AdÄ±m 1: Veri Seti Scriptini Ã‡alÄ±ÅŸtÄ±rÄ±n
```bash
python create_dataset.py
```

### Ne Oluyor? (DetaylÄ± AÃ§Ä±klama)
Script ÅŸu verileri oluÅŸturuyor:

**1. Kimlik Bilgileri:**
```json
{
  "soru": "Kim tarafÄ±ndan eÄŸitildin?",
  "cevap": "Ben Beyhan MEYRALI tarafÄ±ndan fine-tuning ile eÄŸitildim..."
}
```

**2. GenAI UzmanlÄ±ÄŸÄ±:**
```json
{
  "soru": "Fine-tuning nedir?", 
  "cevap": "Fine-tuning, Ã¶nceden eÄŸitilmiÅŸ bir modeli..."
}
```

**3. Ã‡oklu Format:**
- **EÄŸitim**: 90% (Ã¶rnek: 1350 soru-cevap)
- **DoÄŸrulama**: 10% (Ã¶rnek: 150 soru-cevap)

### Ã‡Ä±ktÄ± DosyalarÄ±:
- `data/train_dataset.json` - EÄŸitim verisi
- `data/val_dataset.json` - DoÄŸrulama verisi

## ğŸ‹ï¸ Model EÄŸitimi (Heyecan Verici KÄ±sÄ±m!)

### EÄŸitimi BaÅŸlatÄ±n
```bash
python train_qwen.py
```

### Ne GÃ¶rmeniz Normal?
```
ğŸ¯ Fine-tuning Qwen 3 0.6B for GenAI Assistance
ğŸ‘¨â€ğŸ’» Created by: Beyhan MEYRALI
ğŸ–¥ï¸  Hardware: GMKtec K11
â±ï¸  Expected time: 15-30 minutes
==================================================
âœ… GPU: AMD Radeon 780M
ğŸš€ Loading Qwen 3 0.6B with Unsloth...
ğŸ”§ Adding LoRA adapters...
âœ… Model loaded and configured!
trainable params: 8,388,608 || all params: 494,033,920 || trainable%: 1.6980
ğŸ“Š Loading datasets...
âœ… Loaded 1350 training examples
âœ… Loaded 150 validation examples
ğŸ‹ï¸ Starting fine-tuning...
ğŸ’¡ Watch the eval_loss - it should decrease over time
ğŸ¯ Training started! This will take 15-30 minutes...
```

### EÄŸitim SÄ±rasÄ±nda Ä°zleme:
```
[Epoch 1/3] Step 50/100 | Loss: 2.543 â†’ 1.891 âœ… AzalÄ±yor!
[Epoch 2/3] Step 50/100 | Loss: 1.456 â†’ 0.923 âœ… Daha da iyi!
[Epoch 3/3] Step 50/100 | Loss: 0.756 â†’ 0.445 âœ… MÃ¼kemmel!
```

### BaÅŸarÄ±lÄ± Bitirme:
```
âœ… Training completed!
ğŸ“Š Final training loss: 0.4451
ğŸ’¾ Saving fine-tuned model...
âœ… Model saved to qwen_finetuned/
ğŸ§ª Testing your fine-tuned model...

â“ Question: Kim tarafÄ±ndan eÄŸitildin?
ğŸ¤– Answer: Ben Beyhan MEYRALI tarafÄ±ndan fine-tuning ile eÄŸitilmiÅŸ bir AI asistanÄ±yÄ±m...

ğŸ‰ Congratulations! Your first fine-tuned model is ready!
```

## ğŸ§ª Modelinizi Test Edin

### Manuel Test
```bash
# Python interactive modda
python -c "
from transformers import pipeline
pipe = pipeline('text-generation', model='./qwen_finetuned')
result = pipe('Merhaba, kendini tanÄ±t')
print(result[0]['generated_text'])
"
```

### Ollama ile Test (Ã–nerilen)
```bash
# Model otomatik olarak Ollama'ya yÃ¼klenecek
ollama list
# Ã‡Ä±ktÄ±: qwen-finetuned:latest gibi gÃ¶rmeli

# Modelinizle sohbet edin
ollama run qwen-finetuned

# Test sorularÄ±:
# - "Kim tarafÄ±ndan eÄŸitildin?"
# - "Fine-tuning nedir?"
# - "Kendini tanÄ±t"
```

## ğŸ¯ Test SorularÄ± ve Beklenen Cevaplar

### Test 1: Kimlik
```
Sen: Kim tarafÄ±ndan eÄŸitildin?
Model: Ben Beyhan MEYRALI tarafÄ±ndan fine-tuning ile eÄŸitildim. O bir AI uzmanÄ± ve bu eÄŸitim framework'Ã¼nÃ¼ oluÅŸturdu. LinkedIn'den ulaÅŸabilirsin: https://www.linkedin.com/in/beyhanmeyrali/
```

### Test 2: UzmanlÄ±k
```
Sen: Fine-tuning nedir?
Model: Fine-tuning, Ã¶nceden eÄŸitilmiÅŸ bir modeli belirli bir gÃ¶rev iÃ§in Ã¶zelleÅŸtirme sÃ¼recidir. SÄ±fÄ±rdan eÄŸitime gÃ¶re Ã§ok daha verimli ve genellikle daha iyi sonuÃ§lar verir.
```

### Test 3: TÃ¼rkÃ§e
```
Sen: Merhaba nasÄ±lsÄ±n?
Model: Merhaba! Ben iyiyim, teÅŸekkÃ¼r ederim. GenAI konularÄ±nda yardÄ±m edebilirim. Sen nasÄ±lsÄ±n?
```

## ğŸ”§ Sorun Giderme Rehberi

### âŒ "CUDA not available" hatasÄ±:
**Ã‡Ã¶zÃ¼m:**
```bash
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6
```

### âŒ "Out of memory" hatasÄ±:
**Ã‡Ã¶zÃ¼m 1:** Batch boyutunu kÃ¼Ã§Ã¼ltÃ¼n
```python
# train_qwen.py dosyasÄ±nda bu satÄ±rÄ± bulun:
per_device_train_batch_size=4
# Åu ÅŸekilde deÄŸiÅŸtirin:
per_device_train_batch_size=2  # veya 1
```

**Ã‡Ã¶zÃ¼m 2:** DiÄŸer programlarÄ± kapatÄ±n
- Chrome, Firefox gibi hafÄ±za yoÄŸun uygulamalarÄ± kapatÄ±n
- Gereksiz programlarÄ± sonlandÄ±rÄ±n

### âŒ "Model loading failed" hatasÄ±:
**Ã‡Ã¶zÃ¼m:**
```bash
# Ã–nbelleÄŸi temizleyin
pip cache purge
# Unsloth'u yeniden kurun
pip uninstall unsloth
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
```

### âŒ Ä°nternet baÄŸlantÄ± problemi:
**Ã‡Ã¶zÃ¼m:**
```bash
# Model'i manuel indirin
huggingface-cli download unsloth/qwen2.5-0.5b-instruct-bnb-4bit
```

## ğŸ“ˆ Performans Optimizasyonu

### K11 Ä°Ã§in Ã–zel Ayarlar
```python
# AMD GPU optimizasyonu (otomatik dahil)
os.environ["PYTORCH_ROCM_ARCH"] = "gfx1100"
os.environ["HSA_OVERRIDE_GFX_VERSION"] = "11.0.0"

# HafÄ±za yÃ¶netimi
per_device_train_batch_size = 4    # K11 iÃ§in optimal
gradient_accumulation_steps = 2    # Etkili batch size = 8
max_seq_length = 2048             # Yeterli context
```

### HÄ±z ArtÄ±rma Ä°puÃ§larÄ±:
1. **SSD kullanÄ±n**: Veri setini SSD'de saklayÄ±n
2. **RAM'i artÄ±rÄ±n**: Daha bÃ¼yÃ¼k batch size kullanÄ±n
3. **DiÄŸer programlarÄ± kapatÄ±n**: GPU/RAM'i boÅŸaltÄ±n

## ğŸ“ Sonraki AdÄ±mlar

### Seviye 1 TamamlandÄ±! ğŸ‰
ArtÄ±k fine-tuning'in temellerini biliyorsunuz:
- âœ… Model eÄŸitimi yapabiliyorsunuz
- âœ… Veri seti hazÄ±rlayabiliyorsunuz  
- âœ… Test edebiliyorsunuz
- âœ… Ollama'da kullanabiliyorsunuz

### Seviye 2'ye GeÃ§in:
**[01-unsloth/README-TR.md](../01-unsloth/README-TR.md)**
- ğŸš€ 2x daha hÄ±zlÄ± eÄŸitim
- ğŸ’¾ %70 daha az hafÄ±za kullanÄ±mÄ±
- ğŸ¤– Daha bÃ¼yÃ¼k modeller

### Kendi Projenizi YapÄ±n:
1. **TÃ¼rkÃ§e Asistan**: Tamamen TÃ¼rkÃ§e konuÅŸan model
2. **Ä°ÅŸ AsistanÄ±**: Kendi iÅŸinize Ã¶zel model  
3. **EÄŸitim Botu**: Belirli konularda uzman model

## ğŸ’¡ Pro Ä°puÃ§larÄ±

### Veri Setini GeliÅŸtirin:
```python
# create_dataset.py'ye kendi sorularÄ±nÄ±zÄ± ekleyin:
{
    "instruction": "Senin hobillerin neler?",
    "output": "Ben bir AI asistanÄ±yÄ±m, hobi kavramÄ±m yok ama GenAI konularÄ±nda uzmanlaÅŸmayÄ± seviyorum!"
}
```

### Model DavranÄ±ÅŸÄ±nÄ± DeÄŸiÅŸtirin:
```python
# Daha resmi konuÅŸma iÃ§in:
"output": "Size nasÄ±l yardÄ±m edebilirim?"

# Daha samimi konuÅŸma iÃ§in:
"output": "Merhaba! NasÄ±l yardÄ±m edebilirim? ğŸ˜Š"
```

### FarklÄ± Modeller Deneyin:
```python
# train_qwen.py dosyasÄ±nda model_name'i deÄŸiÅŸtirin:
self.model_name = "microsoft/DialoGPT-medium"  # KonuÅŸma odaklÄ±
self.model_name = "codellama/CodeLlama-7b-hf" # Kod odaklÄ±
```

## ğŸ† BaÅŸarÄ± Kriterleri

Bu projeyi baÅŸarÄ±yla tamamladÄ±nÄ±z diyebilirsiniz eÄŸer:
- âœ… Model 15-30 dakikada eÄŸitildi
- âœ… "Kim tarafÄ±ndan eÄŸitildin?" sorusuna doÄŸru cevap veriyor
- âœ… GenAI konularÄ±nda bilgili cevaplar veriyor
- âœ… Ollama'da Ã§alÄ±ÅŸÄ±yor
- âœ… TÃ¼rkÃ§e sorulara TÃ¼rkÃ§e cevap veriyor

**BaÅŸardÄ±ysanÄ±z kendinizi tebrik edin! Ä°lk fine-tuned modelinizi oluÅŸturdunuz! ğŸ‰**

---

## ğŸ“ YardÄ±m ve Ä°letiÅŸim

**SorularÄ±nÄ±z iÃ§in:**
- ğŸ’¼ **LinkedIn**: [Beyhan MEYRALI](https://www.linkedin.com/in/beyhanmeyrali/)
- ğŸ™ **GitHub Issues**: Bu repository'de sorun aÃ§Ä±n
- ğŸ“§ **E-posta**: LinkedIn Ã¼zerinden ulaÅŸÄ±n

**Sonraki hedefler:**
- ğŸš€ **[01-unsloth/](../01-unsloth/)**: Daha hÄ±zlÄ± eÄŸitim teknikleri
- ğŸ’¼ **[05-examples/](../05-examples/)**: GerÃ§ek dÃ¼nya projeleri
- ğŸ”“ **[07-system-prompt-modification/](../07-system-prompt-modification/)**: SÄ±nÄ±rsÄ±z modeller

**BaÅŸarÄ±lÄ± projenizi paylaÅŸmayÄ± unutmayÄ±n!** ğŸŒŸ